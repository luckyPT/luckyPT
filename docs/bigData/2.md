spark
====
spark是一个快速而通用的集群计算平台。快速的主要原因是在内存进行计算

### 运行模式
**1.本地模式**

**2.standalone模式**

**3.集群模式**<br>
spark与集群资源管理器是松耦合的关系，只需要可以申请到excutor运行所需的进程即可。所以支持多种集群管理组件对spark进行管理。<br>
sparkContext 连接集群资源管理（yarn\k8s\mesos）,申请excutors资源，将相关代码发送到excutors;

**3.1 yarn管理**<br>
使用yarn作为spark集群管理很简单，只需要在使用spark_submit提交任务时，配置HADOOP_CONF_DIR或者YARN_CONF_DIR参数，这时候spark会自动作为yarn的客户端，申请资源（具体来说就是excutors），然后将所需代码传到excutor上，由driver调度执行。<br>
yarn-cluster与yarn-clien模式的区别：<br>

**3.2 mesos**

**3.3 k8s**


### 组件：spark core ###
spark core实现了spark的基本功能：与存储交互、任务调度、内存管理、错误恢复等；<br>
RDD定义：弹性分布式数据集，具有只读-可并行计算-容错性等特点；

### 组件：spark mlib/ml ###

### 组件：spark stream ###

### 组件：spark graphX ###

### 一些优化策略 ###
1.数据倾斜<br>
	表现：个别task执行任务时长远高于其他的task<br>
	解决方案：repartition<br>

2.大数据join小数据<br>
	如果小数据可以被广播，则尽量不用join;<br>
	如果不能广播，可以按照key进行相同的repartition操作；<br>

### 一些问题 ###
1.解析parquet问题：<br>
	异常：org.apache.hadoop.fs.ChecksumException: Checksum error<br>
	问题原因：文件夹内包含一些隐藏的crc文件，这个文件是用于校验使用；如果存在则进行校验<br>
	解决办法：删除隐藏的crc文件<br>
