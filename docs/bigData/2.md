spark
====
spark是一个快速而通用的集群计算平台。快速的主要原因是在内存进行计算

### 运行模式
**1.本地模式**

**2.standalone模式**

**3.集群模式**<br>
spark与集群资源管理器是松耦合的关系，只需要可以申请到excutor运行所需的进程即可。所以支持多种集群管理组件对spark进行管理。<br>
sparkContext 连接集群资源管理（yarn\k8s\mesos）,申请excutors资源，将相关代码发送到excutors;

**3.1 yarn管理**<br>
使用yarn作为spark集群管理很简单，只需要在使用spark_submit提交任务时，配置HADOOP_CONF_DIR或者YARN_CONF_DIR参数，这时候spark会自动作为yarn的客户端，申请资源（具体来说就是excutors），然后将所需代码传到excutor上，由driver调度执行。<br>
yarn-cluster与yarn-clien模式的区别：<br>

**3.2 mesos**

**3.3 k8s**


### 组件：spark core ###
spark core实现了spark的基本功能：与存储交互、任务调度、内存管理、错误恢复等；<br>
**RDD**

弹性分布式数据集(resilient distributed dataset)，具有只读-可并行计算-容错性等特点；可以由hdfs文件（包含hbase等各类以hdfs为基础的数据源）或者scala集合来创建RDD。RDD支持转换(transformations)和动作(actions)两类算子,前者主要是基于已有的RDD创建新的RDD，后者是将在rdd上计算的将结果传给driver program。

transformations类操作具有惰性（lazy），仅当action操作需要结果时才执行，这个特性也是spark更加高效的原因之一。默认情况下，每一次action都会触发与之相关的transformations，如果一个rdd会多次使用，建议进行持久化或者缓存。

transformation类型操作

操作|含义
--|--
map|-
filter|-
flatMap|-
mapPartitions|-
mapPartitionsWithIndex|-
sample|-
union|-
intersection|-
distinct|-
groupByKey|-
reduceByKey|-
aggregateByKey|-
sortByKey|-
join|-
cogroup|-
cartesian|-
pipe|-
coalesce|-
repartition|-
repartitionAndSortWithinPartitions|-



**Dataset**

### 组件：spark mlib/ml ###

### 组件：spark stream ###

### 组件：spark graphX ###

### 一些优化策略 ###
1.数据倾斜<br>
	表现：个别task执行任务时长远高于其他的task<br>
	解决方案：repartition<br>

2.大数据join小数据<br>
	如果小数据可以被广播，则尽量不用join;<br>
	如果不能广播，可以按照key进行相同的repartition操作；<br>

### 一些问题 ###
1.解析parquet问题：<br>
	异常：org.apache.hadoop.fs.ChecksumException: Checksum error<br>
	问题原因：文件夹内包含一些隐藏的crc文件，这个文件是用于校验使用；如果存在则进行校验<br>
	解决办法：删除隐藏的crc文件<br>
