大数据调优心得
====
## 终极办法
利用map-reduce思想，将大数据拆成小数据，分别进行处理，然后汇总；

## 调优
遇见执行时间太长，资源消耗大，OOM等问题需要进行优化时，一方面依赖于经验，另一方面依赖于调参 → 验证效果整个流程的效率；

### 经验
**join过程遇见数据倾斜**<br>
首先统计key的数量，看看数据倾斜情况<br>
- 如果数据量不大，将小数据转为map，不使用join算法
- 如果数据量偏大，不适合转为map，可以对key统一加随机字符串进行打散
- 头部的key处理成map，其余的进行join

### 效率
- 将不需要调整、验证的数据处理逻辑进行保存或者快照，避免每次都需要耗时处理
- 利用client模式，交互式的调整验证，提高效率

### 流程优化
- 长任务流需要进行合理拆分为多个任务，避免某一个逻辑失败后，回溯全部逻辑，同时一定程度上有利于复用，这与软件架构拆分有相同之处；
- 数据质量需要进行监控，比如：每天的记录数、数据总量、缺失值占比等等；类似于软件设计中的日志功能
关于拆分和监控往往会牺牲一定的性能（比如：增加耗时、数据存储等），换来可维护性
