逻辑回归
====
逻辑回归是解决分类问题最基本的模型，对于机器学习系统项目的搭建与开发来说，常常作为baseline；简单快速，性价比很高。

逻辑回归的预测函数形式为```y=1/(1+exp(-f(x)))``` 其中 ```f(x)=kx+b```

其中sigmod函数的形式为 ```y=1/(1+e^(-x))```  用来作为非线性激活函数，将最终f(x)最终的打分映射为0到1之间的数；

sigmod函数有两个特点：
- 函数单调递增，函数值范围在0到1之间，并且关于(0,0.5)对称；当x>0是，函数值大于0.5 x<0时，函数值小于0.5
- 函数的导数可以利用其自身表示，```f(x)```的导数等于```f(x)*(1-f(x))```

### 依然从损失函数说起 ###
![损失函数](/docs/ml/images/3-1.jpg)

损失函数的最终形式是交叉熵的形式，而推导过程最初是设定是最大似然估计，只不过后面经过推导转化，最终转成了交叉熵的形式；

数学求解上类似于线性回归，依然使用梯度下降法求解；结合sigmod函数的特点，最终导数的形式与线性回归是一样的

>除了梯度下降之外，对于逻辑回归和线性回归来说，常用的迭代求解方法还有***牛顿法、拟牛顿法、共轭梯度发、BFGS、L-BFGS等***
