集成决策树：随机森林&GBDT&XGBOOST
====
#### 随机森林 ####


#### GBDT ####


#### XGBOOST ####
从损失函数说起，对于传统的算法来说损失函数一般包含两部分：一部分用来衡量真实值与预测值之间的误差称为训练损失，另一部分用来衡量模型的复杂程度作为惩罚项成为正则项；

通用的表示方式如下：```obj(θ)=L(θ)+Ω(θ)``` 其中L(θ) 表示训练损失，Ω(θ)表示正则项。

xgboost采用CART树作为最基分类器，CART树与其他分类树不同的是，每个叶子节点对应一个打分值；多棵树可以组合为一个分类器，然后将每棵树的分值相加作为最终的score：

>![模型打分](/docs/ml/images/8-1.jpg)  <br>其中fk(xi) 表示第k棵树对样本点xi的打分;
