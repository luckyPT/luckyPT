集成学习算法
====
集成学习的核心思想是多个弱分类器组合成强分类器。下面先介绍一个简单的多分类器组成强分类的例子<br>
> 假如有三个弱分类器进行某项二分类任务的正确率都是0.6；现在组合一个分类器，组合后的分类器按照投票结果，取票数最多的结果作为最终结果；那么这个分类器的正确率为：三个都分类正确的概率 + 两个分类正确的概率 = 0.6^3 + 3 * 0.6 * 0.6 * 0.4 = 0.648

那么什么样的弱分类器可以组合成强分类器呢？ 一句话概括就是“好而不同”的基分类器；也就是说基分类器最好是满足两个特点：效果好、彼此之间差异大（或者说是彼此之间独立性高）<br>
集成学习算法可以分为两类，Bagging和Boosting，下面详细介绍

#### Boosting ####

