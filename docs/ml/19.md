Transformer
====
### 简介
transformer模型比较复杂，涉及到的东西多，但并不是太难；本质上依然是Encoder-Decoder架构，只不过在当中引入了：位置编码、self-attention、多头注意力、paddingMask和lookaheadMask以及经典的残差连接和归一化等，概念比较多，所以无论是理论还是实现都略微复杂，但并不是很难；
