神经网络
====
神经网络与深度学习是继线性回归、逻辑回归、SVM、决策树、贝叶斯等传统机器学习算法之后，新兴的机器学习算法；

相比于传统的机器学习，拥有更强的拟合能力，在某些场景下(如：图片识别，语音识别，自然语言处理等)比传统的机器学习效果要好很多。但是模型的训练需要很强的算力与数据的支撑。

典型的神经网络处理回归问题如下图所示：
![神经网络处理回归问题](/docs/ml/images/9-1.jpg)
虽然看起来可能有点复杂，但其中的数学原理并不难懂，只是计算量大一些；上图中w为权重，对于一个训练好的模型，这些权重都是已知的，根据输入的x1 x2 x3就可以计算出y值。

#### 神经网络参数的求解 ####

从损失函数说起，神经网络的损失函数与线性回归、逻辑回归的损失函数相同。神经网络参数的求解与线性回归、逻辑回归的求解方式也是一样的，同样采用梯度下降法进行求解。差异之处在于，求解损失函数对某些权重的导数(梯度)时，需要用到链式求导。

比如，如果求解损失函数对w111的导数，那么需要先求解损失函数对输出值y^的导数，再求y对l21、l22、l23、l24神经元的导数，然后求这四个神经元对l11的导数，然后求l11对w111的导数。通过这样的链式求导，去求损失函数对权重的导数；由于求前面（如第一层）权重导数的时候，需要先求后面神经网络层的导数，依次向前传递；所以这个求解过程又叫反向传播。
